{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, droprate1=0.5, droprate2=0.5):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('conv1', nn.Conv2d(1, 20, kernel_size=5, padding=2))\n",
    "        self.model.add_module('dropout1', nn.Dropout2d(p=droprate1))\n",
    "        self.model.add_module('maxpool1', nn.MaxPool2d(2, stride=2))\n",
    "        self.model.add_module('conv2', nn.Conv2d(20, 50, kernel_size=5, padding=2))\n",
    "        self.model.add_module('dropout2', nn.Dropout2d(p=droprate1))\n",
    "        self.model.add_module('maxpool2', nn.MaxPool2d(2, stride=2))\n",
    "        self.model.add_module('flatten', Flatten())\n",
    "        self.model.add_module('dense3', nn.Linear(50*7*7, 500))\n",
    "        self.model.add_module('relu3', nn.ReLU())\n",
    "        self.model.add_module('dropout3', nn.Dropout(p=droprate2))\n",
    "        self.model.add_module('final', nn.Linear(500, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "class LeNetClassifier:\n",
    "    def __init__(self, droprate1=0.5, droprate2=0.5, batch_size=128, max_epoch=300, lr=0.01):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epoch = max_epoch\n",
    "        self.lr = lr\n",
    "        self.model = LeNet(droprate1, droprate2)\n",
    "        self.model.cuda()\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.loss_ = []\n",
    "        self.test_error = []\n",
    "        self.test_error_ep = []\n",
    "        self.test_accuracy = []\n",
    "        self.test_accuracy_ep = []\n",
    "\n",
    "    def fit(self, trainset, testset, verbose=True):\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=self.batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "        X_test, y_test = iter(testloader).next()\n",
    "        X_test = X_test.cuda()\n",
    "        #print(self.model)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            running_loss = 0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()  # change\n",
    "            self.loss_.append(running_loss / len(trainloader))\n",
    "            if verbose:\n",
    "                print('Epoch {} loss: {}'.format(epoch+1, self.loss_[-1]))\n",
    "            \n",
    "            #y_test_pred = self.predict(X_test).cpu()\n",
    "            y_test_pred, y_test_pred_ep = self.predict_ep(X_test)\n",
    "            \n",
    "            self.test_accuracy.append(np.mean(y_test.data.numpy() == y_test_pred))\n",
    "            self.test_accuracy_ep.append(np.mean(y_test.data.numpy() == y_test_pred_ep))\n",
    "            \n",
    "            self.test_error.append(int(len(testset)*(1-self.test_accuracy[-1])))\n",
    "            self.test_error_ep.append(int(len(testset)*(1-self.test_accuracy_ep[-1])))\n",
    "            \n",
    "            if verbose:\n",
    "                print('Test error: {}; test accuracy: {:4f}; test accuracy ep: {:4f}'.format(self.test_error[-1], self.test_accuracy[-1], self.test_accuracy_ep[-1]))\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        model = self.model.eval()\n",
    "        outputs = model(Variable(x))\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        model = self.model.train()\n",
    "        return pred\n",
    "\n",
    "    def predict_ep(self, x, T=100):\n",
    "        standard_pred = self.predict(x).cpu().numpy()\n",
    "        y1 = []\n",
    "        y2 = []\n",
    "        for _ in range(T):\n",
    "            _y1 = self.model(Variable(x))\n",
    "            _y2 = F.softmax(_y1, dim=1)\n",
    "            y1.append(_y1.data.cpu().numpy())\n",
    "            y2.append(_y2.data.cpu().numpy())\n",
    "        \n",
    "        y2 = np.array(y2)\n",
    "        pred = np.argmax(np.mean(y2, axis=0), axis=1)\n",
    "        \n",
    "        standard_pred = standard_pred.cpu().numpy()\n",
    "        \n",
    "        return standard_pred, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \\\n",
    "                                transforms.Normalize((0,), (1,))]) # change\n",
    "\n",
    "trainset = datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='data/', train=False, transform=transform)\n",
    "\n",
    "\n",
    "# Define networks\n",
    "lenet1 = [LeNetClassifier(droprate1=0, droprate2=0, max_epoch=600),\n",
    "          LeNetClassifier(droprate1=0, droprate2=0.5, max_epoch=600),\n",
    "          LeNetClassifier(droprate1=0.5, droprate2=0.5, max_epoch=600)]\n",
    "\n",
    "# Training, set verbose=True to see loss after each epoch.\n",
    "[lenet.fit(trainset, testset,verbose=False) for lenet in lenet1]\n",
    "\n",
    "# Save torch models\n",
    "for ind, lenet in enumerate(lenet1):\n",
    "    torch.save(lenet.model, 'mnist_lenet1_'+str(ind)+'.pth')\n",
    "    # Prepare to save errors\n",
    "    lenet.test_error = list(map(str, lenet.test_error))\n",
    "    lenet.test_error_ep = list(map(str, lenet.test_error_ep))\n",
    "\n",
    "# Save test errors to plot figures\n",
    "open(\"lenet1_test_errors.txt\",\"w\").write('\\n'.join([','.join(lenet.test_error) for lenet in lenet1]))\n",
    "open(\"lenet1_test_errors_ep.txt\",\"w\").write('\\n'.join([','.join(lenet.test_error_ep) for lenet in lenet1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved test errors to plot figures.\n",
    "lenet1_test_errors = [error_array.split(',') for error_array in open(\"lenet1_test_errors.txt\",\"r\").read().split('\\n')]\n",
    "lenet1_test_errors = np.array(lenet1_test_errors,dtype='f')\n",
    "\n",
    "\n",
    "labels = ['LeNet no dropout',\n",
    "          'LeNet IP dropout',\n",
    "          'LeNet All dropout']\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "for i, r in enumerate(mlp1_test_errors.tolist() + lenet1_test_errors.tolist()):\n",
    "    plt.plot(range(1, len(r)+1), r, '.-', label=labels[i], alpha=0.6);\n",
    "plt.ylim([50, 250]);\n",
    "plt.legend(loc=1);\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Number of errors in test set');\n",
    "plt.title('Test Error on MNIST Dataset for All Networks')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
