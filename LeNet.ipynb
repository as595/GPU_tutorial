{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs        = 10\n",
    "batch_size    = 32                  # number of samples per batch\n",
    "imsize        = 28\n",
    "num_classes   = 10                  # The number of output classes. In this case, from 0 to 9\n",
    "learning_rate = torch.tensor(1e-2)  # The speed of convergence\n",
    "momentum      = torch.tensor(9e-1)  # momentum for optimizer\n",
    "decay         = torch.tensor(5e-4)  # weight decay for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = datasets.MNIST('data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, imsize, kernel_size=5, drop1=0, drop2=0.5):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        z = 5\n",
    "        \n",
    "        self.conv1  = nn.Conv2d(in_chan, 6, kernel_size, padding=2)\n",
    "        self.conv2  = nn.Conv2d(6, 16, kernel_size)\n",
    "        self.fc1    = nn.Linear(16*z*z, 120)\n",
    "        self.fc2    = nn.Linear(120, 84)\n",
    "        self.fc3    = nn.Linear(84, out_chan)\n",
    "        self.drop2d = nn.Dropout2d(p=drop1)\n",
    "        self.drop   = nn.Dropout(p=drop2)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def enable_dropout(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Dropout):\n",
    "                m.train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.drop2d(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.drop2d(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(in_chan=1, out_chan=num_classes, imsize=imsize, kernel_size=5, drop1=0, drop2=0.5).to(device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "         Dropout2d-2            [-1, 6, 28, 28]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         Dropout2d-4           [-1, 16, 10, 10]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "           Dropout-6                  [-1, 120]               0\n",
      "            Linear-7                   [-1, 84]          10,164\n",
      "           Dropout-8                   [-1, 84]               0\n",
      "            Linear-9                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.08791932333971168, Accuracy: 0.9719448881789138\n",
      "Epoch: 1, Loss: 0.05949718490429483, Accuracy: 0.9838258785942492\n",
      "Epoch: 2, Loss: 0.058786239978726604, Accuracy: 0.983526357827476\n",
      "Epoch: 3, Loss: 0.04681262281884263, Accuracy: 0.9863218849840255\n",
      "Epoch: 4, Loss: 0.04564482418936677, Accuracy: 0.9868210862619808\n",
      "Epoch: 5, Loss: 0.03939377796039701, Accuracy: 0.987120607028754\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "epoch_trainaccs, epoch_testaccs = [], []\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    model.train()\n",
    "    train_accs=[]; acc = 0\n",
    "    for batch, (x_train, y_train) in enumerate(train_loader):\n",
    "        \n",
    "        x_train = x_train.to(device=device)\n",
    "        y_train = y_train.to(device=device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        pred = model(x_train)\n",
    "        loss = F.cross_entropy(pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (pred.argmax(dim=-1) == y_train).to(torch.float32).mean()\n",
    "        train_accs.append(acc.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_losses, test_accs = [], []; acc = 0\n",
    "        for i, (x_test, y_test) in enumerate(test_loader):\n",
    "            \n",
    "            x_test = x_test.to(device=device)\n",
    "            y_test = y_test.to(device=device)\n",
    "            \n",
    "            test_pred = model(x_test)\n",
    "            loss = F.cross_entropy(test_pred, y_test)\n",
    "            \n",
    "            acc = (test_pred.argmax(dim=-1) == y_test).to(torch.float32).mean()\n",
    "            test_losses.append(loss.item())\n",
    "            test_accs.append(acc.mean().item())\n",
    "\n",
    "    if verbose:\n",
    "        print('Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch, np.mean(test_losses), np.mean(test_accs)))\n",
    "        \n",
    "    epoch_trainaccs.append(np.mean(train_accs))\n",
    "    epoch_testaccs.append(np.mean(test_accs))\n",
    "    \n",
    "if use_cuda: torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "print(\"Run time [s]: \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished Training', iter)\n",
    "print(\"Final test error: \",100.*(1 - epoch_testaccs[-1]))\n",
    "\n",
    "np.savez(\"./mnist_lenet_none.npz\",epoch_testaccs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
