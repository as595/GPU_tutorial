{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the PyTorch components that we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then some standard library imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This next cell contains all the user defined variables for running our network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples       = ['ggH125_ZZ4lep','llll'] # datafiles for input\n",
    "epochs        = 100                      # number of training epochs\n",
    "batch_size    = 32                       # number of samples per batch\n",
    "input_size    = 2                        # The number of features\n",
    "num_classes   = 2                        # The number of output classes. In this case: [star, galaxy, quasar]\n",
    "hidden_size   = 5                        # The number of nodes at the hidden layer\n",
    "learning_rate = 1e-3                     # The speed of convergence\n",
    "verbose       = True                     # flag for printing out stats at each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "First import the data and apply the same pre-processing as outlined in the [ML Tutorial](https://hsf-training.github.io/hsf-training-ml-webpage/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames = {} # define empty dictionary to hold dataframes\n",
    "for s in samples: # loop over samples\n",
    "    DataFrames[s] = pd.read_csv('./'+s+\".csv\") # read .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on lepton charge\n",
    "def cut_lep_charge(lep_charge_0,lep_charge_1,lep_charge_2,lep_charge_3):\n",
    "# only want to keep events where sum of lepton charges is 0\n",
    "    sum_lep_charge = lep_charge_0 + lep_charge_1 + lep_charge_2 + lep_charge_3\n",
    "    if sum_lep_charge==0: return True\n",
    "    else: return False\n",
    "\n",
    "# apply cut on lepton charge\n",
    "for s in samples:\n",
    "    # cut on lepton charge using the function cut_lep_charge defined above\n",
    "    DataFrames[s] = DataFrames[s][ np.vectorize(cut_lep_charge)(DataFrames[s].lep_charge_0,\n",
    "                                                    \t    DataFrames[s].lep_charge_1,\n",
    "                                                    \t    DataFrames[s].lep_charge_2,\n",
    "                                                    \t    DataFrames[s].lep_charge_3) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Then create the *feature* and *target* data arrays that are needed to train the machine learning model. Again this follows the [ML tutorial](https://hsf-training.github.io/hsf-training-ml-webpage/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_inputs = ['lep_pt_1','lep_pt_2'] # list of features for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_MC = [] # define empty list that will contain all features for the MC\n",
    "\n",
    "for s in samples: # loop over the different samples\n",
    "    if s!='data': # only MC should pass this\n",
    "        all_MC.append(DataFrames[s][ML_inputs]) # append the MC dataframe to the list containing all MC features\n",
    "        \n",
    "X = np.concatenate(all_MC) # concatenate the list of MC dataframes into a single 2D array of features, called X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = [] # define empty list that will contain labels whether an event in signal or background\n",
    "\n",
    "for s in samples: # loop over the different samples\n",
    "    if s!='data': # only MC should pass this\n",
    "        if 'H125' in s: # only signal MC should pass this\n",
    "            all_y.append(np.ones(DataFrames[s].shape[0])) # signal events are labelled with 1\n",
    "        else: # only background MC should pass this\n",
    "            all_y.append(np.zeros(DataFrames[s].shape[0])) # background events are labelled 0\n",
    "            \n",
    "y = np.concatenate(all_y) # concatenate the list of lables into a single 1D array of labels, called y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                  test_size=0.33, \n",
    "                                                  random_state=492 ) # set the random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # initialise StandardScaler\n",
    "\n",
    "scaler.fit(X_train) # Fit only to the training data\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Here we're making use of the PyTorch `DataLoader` functionality. This is going to be useful later when we want to load data during our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train  = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_train, y_train = Variable(X_train), Variable(y_train)\n",
    "\n",
    "x_valid, y_valid = X_train[:100], y_train[:100]\n",
    "x_train_nn, y_train_nn = X_train[100:], y_train[100:]\n",
    "\n",
    "train_data = Data.TensorDataset(x_train_nn, y_train_nn)\n",
    "valid_data = Data.TensorDataset(x_valid, y_valid)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True)\n",
    "\n",
    "valid_loader = Data.DataLoader(dataset=valid_data,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Here we define the neural network that we'll be using. This is a simple fully-connected neural network, otherwise known as a *multi-layer perceptron* (MLP). It has two hidden layers, both with the same number of neurons (`hidden_dim`). The order of the layers for a forward pass through the network is specified in the `forward` function. You can see that each fully-connected layer is followed by a [ReLU activation function](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#relu). The function then returns an unnormalised vector of outputs (`x`; also referred to as *logits*) and a vector of normalised \"probabilities\" for `x`, calculated using the [SoftMax function](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h1  = nn.Linear(in_dim, hidden_dim)\n",
    "        self.h2  = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, out_dim)\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.relu(self.h2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x, F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to specify that we're using the `Classifier_MLP` model that we specified above and pass it the parameters it requires (`input_size`, `hidden_dim`, `out_dim`). \n",
    "\n",
    "We also specify which optimizer we'll use to train our network. Here I've implemented a classic [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) (SGD) optimiser, but there are [a wide range of optimizers available in the PyTorch library](https://pytorch.org/docs/stable/optim.html#algorithms). For most recent applications the [Adam](https://arxiv.org/abs/1412.6980) optimizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier_MLP(in_dim=input_size, hidden_dim=hidden_size, out_dim=num_classes)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains the training loop for optimizing the parameters of our neural network. To train the network we loop through the full training data set multiple times. Each loop is called an *epoch*. However, we don't read the full dataset all at once in an individual epoch, instead we split it into *mini-batches* and we use the optimization algorithm to update the network parameters after each batch. \n",
    "\n",
    "The `train_loader` that we specified earlier using the PyTorch `DataLoader` breaks up the full dataset into batches automatically and allows us to load the feature data (`x_train`) and the label data (`y_train`) for each batch separately. Moreover, because we specified `shuffle=True` when we defined the `train_loader` the full datasets will be shuffled on each epoch, so that we aren't optimising over an identical sequence of samples in every loop. \n",
    "\n",
    "PyTorch models (`nn.Module`) can be set into either training or evaluation mode. For the loop we've defined here this setting does not make any difference as we do not use any layers that perform differently during evaluation (e.g. dropout, batch normalisation, etc. ) However, it's included here for completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.498926\n",
      "Validation Loss: 0.511915, Validation Accuracy: 0.680000\n",
      "Epoch: 1, Train Loss: 0.416348\n",
      "Validation Loss: 0.458114, Validation Accuracy: 0.680000\n",
      "Epoch: 2, Train Loss: 0.404610\n",
      "Validation Loss: 0.450099, Validation Accuracy: 0.680000\n",
      "Epoch: 3, Train Loss: 0.401071\n",
      "Validation Loss: 0.444710, Validation Accuracy: 0.680000\n",
      "Epoch: 4, Train Loss: 0.397758\n",
      "Validation Loss: 0.439354, Validation Accuracy: 0.730000\n",
      "Epoch: 5, Train Loss: 0.394308\n",
      "Validation Loss: 0.431247, Validation Accuracy: 0.810000\n",
      "Epoch: 6, Train Loss: 0.390859\n",
      "Validation Loss: 0.425267, Validation Accuracy: 0.790000\n",
      "Epoch: 7, Train Loss: 0.387606\n",
      "Validation Loss: 0.418356, Validation Accuracy: 0.800000\n",
      "Epoch: 8, Train Loss: 0.384678\n",
      "Validation Loss: 0.414951, Validation Accuracy: 0.810000\n",
      "Epoch: 9, Train Loss: 0.382122\n",
      "Validation Loss: 0.409372, Validation Accuracy: 0.800000\n",
      "Epoch: 10, Train Loss: 0.380047\n",
      "Validation Loss: 0.408139, Validation Accuracy: 0.790000\n",
      "Epoch: 11, Train Loss: 0.378408\n",
      "Validation Loss: 0.408740, Validation Accuracy: 0.790000\n",
      "Epoch: 12, Train Loss: 0.377062\n",
      "Validation Loss: 0.405930, Validation Accuracy: 0.790000\n",
      "Epoch: 13, Train Loss: 0.375885\n",
      "Validation Loss: 0.406484, Validation Accuracy: 0.790000\n",
      "Epoch: 14, Train Loss: 0.374881\n",
      "Validation Loss: 0.404327, Validation Accuracy: 0.780000\n",
      "Epoch: 15, Train Loss: 0.374069\n",
      "Validation Loss: 0.402421, Validation Accuracy: 0.780000\n",
      "Epoch: 16, Train Loss: 0.373488\n",
      "Validation Loss: 0.403074, Validation Accuracy: 0.790000\n",
      "Epoch: 17, Train Loss: 0.373095\n",
      "Validation Loss: 0.403104, Validation Accuracy: 0.790000\n",
      "Epoch: 18, Train Loss: 0.372848\n",
      "Validation Loss: 0.399851, Validation Accuracy: 0.790000\n",
      "Epoch: 19, Train Loss: 0.372690\n",
      "Validation Loss: 0.401707, Validation Accuracy: 0.790000\n",
      "Epoch: 20, Train Loss: 0.372563\n",
      "Validation Loss: 0.400092, Validation Accuracy: 0.790000\n",
      "Epoch: 21, Train Loss: 0.372473\n",
      "Validation Loss: 0.398732, Validation Accuracy: 0.790000\n",
      "Epoch: 22, Train Loss: 0.372382\n",
      "Validation Loss: 0.398913, Validation Accuracy: 0.790000\n",
      "Epoch: 23, Train Loss: 0.372313\n",
      "Validation Loss: 0.399596, Validation Accuracy: 0.790000\n",
      "Epoch: 24, Train Loss: 0.372224\n",
      "Validation Loss: 0.400805, Validation Accuracy: 0.800000\n",
      "Epoch: 25, Train Loss: 0.372146\n",
      "Validation Loss: 0.397953, Validation Accuracy: 0.800000\n",
      "Epoch: 26, Train Loss: 0.372072\n",
      "Validation Loss: 0.397959, Validation Accuracy: 0.810000\n",
      "Epoch: 27, Train Loss: 0.371978\n",
      "Validation Loss: 0.397651, Validation Accuracy: 0.800000\n",
      "Epoch: 28, Train Loss: 0.371878\n",
      "Validation Loss: 0.397248, Validation Accuracy: 0.800000\n",
      "Epoch: 29, Train Loss: 0.371766\n",
      "Validation Loss: 0.396437, Validation Accuracy: 0.800000\n",
      "Epoch: 30, Train Loss: 0.371648\n",
      "Validation Loss: 0.398278, Validation Accuracy: 0.800000\n",
      "Epoch: 31, Train Loss: 0.371582\n",
      "Validation Loss: 0.394896, Validation Accuracy: 0.800000\n",
      "Epoch: 32, Train Loss: 0.371501\n",
      "Validation Loss: 0.397031, Validation Accuracy: 0.800000\n",
      "Epoch: 33, Train Loss: 0.371451\n",
      "Validation Loss: 0.395674, Validation Accuracy: 0.790000\n",
      "Epoch: 34, Train Loss: 0.371406\n",
      "Validation Loss: 0.395211, Validation Accuracy: 0.800000\n",
      "Epoch: 35, Train Loss: 0.371367\n",
      "Validation Loss: 0.394831, Validation Accuracy: 0.800000\n",
      "Epoch: 36, Train Loss: 0.371347\n",
      "Validation Loss: 0.395625, Validation Accuracy: 0.800000\n",
      "Epoch: 37, Train Loss: 0.371314\n",
      "Validation Loss: 0.394434, Validation Accuracy: 0.800000\n",
      "Epoch: 38, Train Loss: 0.371300\n",
      "Validation Loss: 0.394564, Validation Accuracy: 0.800000\n",
      "Epoch: 39, Train Loss: 0.371288\n",
      "Validation Loss: 0.395695, Validation Accuracy: 0.790000\n",
      "Epoch: 40, Train Loss: 0.371273\n",
      "Validation Loss: 0.393406, Validation Accuracy: 0.800000\n",
      "Epoch: 41, Train Loss: 0.371262\n",
      "Validation Loss: 0.393803, Validation Accuracy: 0.800000\n",
      "Epoch: 42, Train Loss: 0.371248\n",
      "Validation Loss: 0.393218, Validation Accuracy: 0.800000\n",
      "Epoch: 43, Train Loss: 0.371234\n",
      "Validation Loss: 0.392953, Validation Accuracy: 0.800000\n",
      "Epoch: 44, Train Loss: 0.371235\n",
      "Validation Loss: 0.393192, Validation Accuracy: 0.800000\n",
      "Epoch: 45, Train Loss: 0.371221\n",
      "Validation Loss: 0.394730, Validation Accuracy: 0.800000\n",
      "Epoch: 46, Train Loss: 0.371216\n",
      "Validation Loss: 0.396127, Validation Accuracy: 0.810000\n",
      "Epoch: 47, Train Loss: 0.371212\n",
      "Validation Loss: 0.395781, Validation Accuracy: 0.820000\n",
      "Epoch: 48, Train Loss: 0.371194\n",
      "Validation Loss: 0.392518, Validation Accuracy: 0.800000\n",
      "Epoch: 49, Train Loss: 0.371201\n",
      "Validation Loss: 0.392531, Validation Accuracy: 0.800000\n",
      "Epoch: 50, Train Loss: 0.371185\n",
      "Validation Loss: 0.396421, Validation Accuracy: 0.810000\n",
      "Epoch: 51, Train Loss: 0.371194\n",
      "Validation Loss: 0.394397, Validation Accuracy: 0.810000\n",
      "Epoch: 52, Train Loss: 0.371167\n",
      "Validation Loss: 0.391127, Validation Accuracy: 0.790000\n",
      "Epoch: 53, Train Loss: 0.371174\n",
      "Validation Loss: 0.395761, Validation Accuracy: 0.800000\n",
      "Epoch: 54, Train Loss: 0.371177\n",
      "Validation Loss: 0.396186, Validation Accuracy: 0.820000\n",
      "Epoch: 55, Train Loss: 0.371151\n",
      "Validation Loss: 0.394741, Validation Accuracy: 0.800000\n",
      "Epoch: 56, Train Loss: 0.371159\n",
      "Validation Loss: 0.395133, Validation Accuracy: 0.810000\n",
      "Epoch: 57, Train Loss: 0.371156\n",
      "Validation Loss: 0.394734, Validation Accuracy: 0.800000\n",
      "Epoch: 58, Train Loss: 0.371157\n",
      "Validation Loss: 0.393209, Validation Accuracy: 0.800000\n",
      "Epoch: 59, Train Loss: 0.371150\n",
      "Validation Loss: 0.392423, Validation Accuracy: 0.800000\n",
      "Epoch: 60, Train Loss: 0.371138\n",
      "Validation Loss: 0.392265, Validation Accuracy: 0.790000\n",
      "Epoch: 61, Train Loss: 0.371153\n",
      "Validation Loss: 0.394358, Validation Accuracy: 0.800000\n",
      "Epoch: 62, Train Loss: 0.371139\n",
      "Validation Loss: 0.395490, Validation Accuracy: 0.810000\n",
      "Epoch: 63, Train Loss: 0.371135\n",
      "Validation Loss: 0.395323, Validation Accuracy: 0.810000\n",
      "Epoch: 64, Train Loss: 0.371126\n",
      "Validation Loss: 0.392961, Validation Accuracy: 0.800000\n",
      "Epoch: 65, Train Loss: 0.371126\n",
      "Validation Loss: 0.393954, Validation Accuracy: 0.800000\n",
      "Epoch: 66, Train Loss: 0.371115\n",
      "Validation Loss: 0.395866, Validation Accuracy: 0.810000\n",
      "Epoch: 67, Train Loss: 0.371124\n",
      "Validation Loss: 0.393922, Validation Accuracy: 0.810000\n",
      "Epoch: 68, Train Loss: 0.371101\n",
      "Validation Loss: 0.395263, Validation Accuracy: 0.820000\n",
      "Epoch: 69, Train Loss: 0.371112\n",
      "Validation Loss: 0.393938, Validation Accuracy: 0.810000\n",
      "Epoch: 70, Train Loss: 0.371091\n",
      "Validation Loss: 0.392481, Validation Accuracy: 0.800000\n",
      "Epoch: 71, Train Loss: 0.371097\n",
      "Validation Loss: 0.395137, Validation Accuracy: 0.800000\n",
      "Epoch: 72, Train Loss: 0.371099\n",
      "Validation Loss: 0.393306, Validation Accuracy: 0.800000\n",
      "Epoch: 73, Train Loss: 0.371100\n",
      "Validation Loss: 0.393724, Validation Accuracy: 0.800000\n",
      "Epoch: 74, Train Loss: 0.371084\n",
      "Validation Loss: 0.391682, Validation Accuracy: 0.790000\n",
      "Epoch: 75, Train Loss: 0.371085\n",
      "Validation Loss: 0.393999, Validation Accuracy: 0.800000\n",
      "Epoch: 76, Train Loss: 0.371090\n",
      "Validation Loss: 0.393111, Validation Accuracy: 0.800000\n",
      "Epoch: 77, Train Loss: 0.371075\n",
      "Validation Loss: 0.392272, Validation Accuracy: 0.800000\n",
      "Epoch: 78, Train Loss: 0.371070\n",
      "Validation Loss: 0.393264, Validation Accuracy: 0.800000\n",
      "Epoch: 79, Train Loss: 0.371070\n",
      "Validation Loss: 0.394470, Validation Accuracy: 0.800000\n",
      "Epoch: 80, Train Loss: 0.371061\n",
      "Validation Loss: 0.394647, Validation Accuracy: 0.800000\n",
      "Epoch: 81, Train Loss: 0.371049\n",
      "Validation Loss: 0.395279, Validation Accuracy: 0.820000\n",
      "Epoch: 82, Train Loss: 0.371032\n",
      "Validation Loss: 0.393097, Validation Accuracy: 0.800000\n",
      "Epoch: 83, Train Loss: 0.371030\n",
      "Validation Loss: 0.392684, Validation Accuracy: 0.800000\n",
      "Epoch: 84, Train Loss: 0.371014\n",
      "Validation Loss: 0.395526, Validation Accuracy: 0.820000\n",
      "Epoch: 85, Train Loss: 0.371027\n",
      "Validation Loss: 0.395207, Validation Accuracy: 0.820000\n",
      "Epoch: 86, Train Loss: 0.371027\n",
      "Validation Loss: 0.394220, Validation Accuracy: 0.810000\n",
      "Epoch: 87, Train Loss: 0.371019\n",
      "Validation Loss: 0.393596, Validation Accuracy: 0.800000\n",
      "Epoch: 88, Train Loss: 0.371010\n",
      "Validation Loss: 0.394645, Validation Accuracy: 0.820000\n",
      "Epoch: 89, Train Loss: 0.371002\n",
      "Validation Loss: 0.394557, Validation Accuracy: 0.810000\n",
      "Epoch: 90, Train Loss: 0.370994\n",
      "Validation Loss: 0.394460, Validation Accuracy: 0.810000\n",
      "Epoch: 91, Train Loss: 0.370985\n",
      "Validation Loss: 0.393762, Validation Accuracy: 0.800000\n",
      "Epoch: 92, Train Loss: 0.370990\n",
      "Validation Loss: 0.394395, Validation Accuracy: 0.820000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, Train Loss: 0.370982\n",
      "Validation Loss: 0.393510, Validation Accuracy: 0.800000\n",
      "Epoch: 94, Train Loss: 0.370969\n",
      "Validation Loss: 0.395051, Validation Accuracy: 0.810000\n",
      "Epoch: 95, Train Loss: 0.370968\n",
      "Validation Loss: 0.394267, Validation Accuracy: 0.810000\n",
      "Epoch: 96, Train Loss: 0.370970\n",
      "Validation Loss: 0.394497, Validation Accuracy: 0.810000\n",
      "Epoch: 97, Train Loss: 0.370955\n",
      "Validation Loss: 0.392335, Validation Accuracy: 0.810000\n",
      "Epoch: 98, Train Loss: 0.370955\n",
      "Validation Loss: 0.392337, Validation Accuracy: 0.810000\n",
      "Epoch: 99, Train Loss: 0.370944\n",
      "Validation Loss: 0.393667, Validation Accuracy: 0.820000\n",
      "Finished Training\n",
      "Final validation error:  18.000000000000004 %\n",
      "Run time [s]:  1025.5836069583893\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "_results = []\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    # training loop for this epoch\n",
    "    model.train() # set the model into training mode\n",
    "    \n",
    "    train_loss = 0.\n",
    "    for batch, (x_train, y_train) in enumerate(train_loader):\n",
    "        \n",
    "        model.zero_grad()\n",
    "        out, prob = model(x_train)\n",
    "        \n",
    "        loss = F.cross_entropy(out, y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * x_train.size(0)\n",
    "    \n",
    "    train_loss/= len(train_loader.dataset)\n",
    "\n",
    "    if verbose:\n",
    "        print('Epoch: {}, Train Loss: {:4f}'.format(epoch, train_loss))\n",
    "\n",
    "    # validation loop for this epoch:\n",
    "    model.eval() # set the model into evaluation mode\n",
    "    with torch.no_grad():  # turn off the gradient calculations\n",
    "        \n",
    "        correct = 0; valid_loss = 0\n",
    "        for i, (x_valid, y_valid) in enumerate(valid_loader):\n",
    "            \n",
    "            out, prob = model(x_valid)\n",
    "            loss = F.cross_entropy(out, y_valid)\n",
    "            \n",
    "            valid_loss += loss.item() * x_valid.size(0)\n",
    "            \n",
    "            preds = prob.argmax(dim=1, keepdim=True)\n",
    "            correct += preds.eq(y_valid.view_as(preds)).sum().item()\n",
    "            \n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "    if verbose:\n",
    "        print('Validation Loss: {:4f}, Validation Accuracy: {:4f}'.format(valid_loss, accuracy))\n",
    "\n",
    "    # create output row:\n",
    "    _results.append([epoch, train_loss, valid_loss, accuracy])\n",
    "\n",
    "results = np.array(_results)\n",
    "print('Finished Training')\n",
    "print(\"Final validation error: \",100.*(1 - accuracy),\"%\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Run time [s]: \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results.shape)\n",
    "\n",
    "pl.subplot(111)\n",
    "pl.plot(results[:,0],results[:,1], label=\"training\")\n",
    "pl.plot(results[:,0],results[:,2], label=\"validation\")\n",
    "pl.xlabel(\"Epoch\")\n",
    "pl.ylabel(\"Loss\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
